{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üî• GPU-Accelerated OrdinalSustain Analysis\n",
    "\n",
    "**Google Colab GPU Setup**\n",
    "\n",
    "This notebook runs your OrdinalSustain analysis on GPU, reducing runtime from **30 days ‚Üí 2-4 days**!\n",
    "\n",
    "## ‚ö° Before You Start:\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí Select **T4 GPU** (free) or **A100 GPU** (Pro)\n",
    "2. **Run cells in order**: Press `Shift + Enter` on each cell\n",
    "3. **Test first**: Run quick test (Cell 6) before full analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpu-check"
   },
   "source": [
    "## 1Ô∏è‚É£ GPU Detection\n",
    "\n",
    "Check if GPU is available and working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell-1"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç GPU DETECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check GPU\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n‚úÖ GPU detected!\\n\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  GPU may not be enabled.\")\n",
    "        print(\"Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n‚ùå GPU is not available.\")\n",
    "    print(\"Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install"
   },
   "source": [
    "## 2Ô∏è‚É£ Install Dependencies\n",
    "\n",
    "Install all required packages (takes ~2-3 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell-2"
   },
   "outputs": [],
   "source": "print(\"=\"*70)\nprint(\"üì¶ INSTALLING DEPENDENCIES\")\nprint(\"=\"*70)\n\n# Install packages (GPU OrdinalSustain only - minimal dependencies)\nprint(\"\\nüì¶ Installing packages for GPU OrdinalSustain...\")\n!pip install -q torch numpy scipy matplotlib tqdm scikit-learn pandas\n\nprint(\"\\n‚úÖ Core dependencies installed!\")\nprint(\"\\n‚ÑπÔ∏è  Note: kde_ebm and awkde are NOT installed (only needed for MixtureSustain)\")\nprint(\"         OrdinalSustain only needs PyTorch + standard scientific packages\")\n\n# Verify PyTorch can see GPU\nimport torch\nprint(f\"\\nüîß PyTorch GPU Info:\")\nprint(f\"   ‚Ä¢ PyTorch version: {torch.__version__}\")\nprint(f\"   ‚Ä¢ CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"   ‚Ä¢ CUDA version: {torch.version.cuda}\")\n    print(f\"   ‚Ä¢ GPU device: {torch.cuda.get_device_name(0)}\")\n    print(f\"   ‚Ä¢ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\nelse:\n    print(\"   ‚ö†Ô∏è  CUDA not available. Please enable GPU runtime.\")\n\nprint(\"\\n‚úÖ All dependencies installed!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone"
   },
   "source": [
    "## 3Ô∏è‚É£ Clone Repository\n",
    "\n",
    "Get the latest GPU-optimized code from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell-3"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üì• CLONING REPOSITORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Remove existing directory if present\n",
    "!rm -rf mphil\n",
    "\n",
    "# Clone repository\n",
    "!git clone https://github.com/Amelia3141/mphil.git\n",
    "%cd mphil\n",
    "\n",
    "# Checkout GPU branch with latest optimizations\n",
    "!git checkout claude/optimize-sustain-speed-011CV4Lk8FuUjS6hZNj13WE3\n",
    "\n",
    "# Add to Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/content/mphil')\n",
    "\n",
    "print(\"\\n‚úÖ Repository ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-prep"
   },
   "source": [
    "## 4Ô∏è‚É£ Prepare Your Data\n",
    "\n",
    "**Option A**: Load your real data (uncomment and edit paths below)\n",
    "**Option B**: Use synthetic test data (runs as-is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell-4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ============================================================================\n",
    "# OPTION A: Load Your Real Data (Uncomment and edit paths)\n",
    "# ============================================================================\n",
    "# prob_nl = np.load('/content/drive/MyDrive/your_data/prob_nl.npy')\n",
    "# prob_score = np.load('/content/drive/MyDrive/your_data/prob_score.npy')\n",
    "# score_vals = np.load('/content/drive/MyDrive/your_data/score_vals.npy')\n",
    "# biomarker_labels = ['Domain1', 'Domain2', 'Domain3', ...]  # Your labels\n",
    "\n",
    "# ============================================================================\n",
    "# OPTION B: Generate Synthetic Test Data (Default)\n",
    "# ============================================================================\n",
    "def generate_test_data(n_subjects=8000, n_biomarkers=13, n_scores=3, seed=42):\n",
    "    \"\"\"Generate synthetic test data for OrdinalSustain.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Probability distributions\n",
    "    p_correct = 0.9\n",
    "    p_nl_dist = np.full((n_scores + 1), (1 - p_correct) / n_scores)\n",
    "    p_nl_dist[0] = p_correct\n",
    "    \n",
    "    p_score_dist = np.full((n_scores, n_scores + 1), (1 - p_correct) / n_scores)\n",
    "    for score in range(n_scores):\n",
    "        p_score_dist[score, score + 1] = p_correct\n",
    "    \n",
    "    # Generate data\n",
    "    data = np.random.choice(range(n_scores + 1), n_subjects * n_biomarkers,\n",
    "                          replace=True, p=p_nl_dist)\n",
    "    data = data.reshape((n_subjects, n_biomarkers))\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    prob_nl = p_nl_dist[data]\n",
    "    \n",
    "    prob_score = np.zeros((n_subjects, n_biomarkers, n_scores))\n",
    "    for n in range(n_biomarkers):\n",
    "        for z in range(n_scores):\n",
    "            for score in range(n_scores + 1):\n",
    "                prob_score[data[:, n] == score, n, z] = p_score_dist[z, score]\n",
    "    \n",
    "    score_vals = np.tile(np.arange(1, n_scores + 1), (n_biomarkers, 1))\n",
    "    biomarker_labels = [f\"Biomarker_{i}\" for i in range(n_biomarkers)]\n",
    "    \n",
    "    return prob_nl, prob_score, score_vals, biomarker_labels\n",
    "\n",
    "# Generate test data (matches your dataset dimensions)\n",
    "prob_nl, prob_score, score_vals, biomarker_labels = generate_test_data(\n",
    "    n_subjects=8000,    # YOUR dataset size\n",
    "    n_biomarkers=13,    # YOUR number of biomarkers  \n",
    "    n_scores=3          # YOUR severity levels\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data ready:\")\n",
    "print(f\"   ‚Ä¢ Subjects: {prob_nl.shape[0]}\")\n",
    "print(f\"   ‚Ä¢ Biomarkers: {prob_nl.shape[1]}\")\n",
    "print(f\"   ‚Ä¢ Severity levels: {prob_score.shape[2]}\")\n",
    "print(f\"\\nData shapes:\")\n",
    "print(f\"   ‚Ä¢ prob_nl: {prob_nl.shape}\")\n",
    "print(f\"   ‚Ä¢ prob_score: {prob_score.shape}\")\n",
    "print(f\"   ‚Ä¢ score_vals: {score_vals.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mount-drive"
   },
   "source": [
    "## üíæ (Optional) Mount Google Drive\n",
    "\n",
    "Uncomment and run this cell if you want to:\n",
    "- Load data from Google Drive\n",
    "- Save results to Google Drive\n",
    "- Preserve results after Colab session ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell-mount-drive"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# print(\"‚úÖ Google Drive mounted at /content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick-test"
   },
   "source": [
    "## 5Ô∏è‚É£ Quick Test (IMPORTANT - Run This First!)\n",
    "\n",
    "**‚ö†Ô∏è Run this before the full analysis!**\n",
    "\n",
    "This test will:\n",
    "- ‚úÖ Verify GPU is working\n",
    "- ‚úÖ Measure actual speedup\n",
    "- ‚úÖ Estimate time for full run\n",
    "\n",
    "Takes ~2-5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell-5"
   },
   "outputs": [],
   "source": "from pySuStaIn.TorchOrdinalSustain import TorchOrdinalSustain\nimport time\nimport os\nfrom datetime import datetime\n\nprint(\"=\"*70)\nprint(\"üß™ QUICK TEST - GPU Speedup Verification\")\nprint(\"=\"*70)\n\n# Create test output directory\ntest_output = \"./test_output\"\nos.makedirs(test_output, exist_ok=True)\n\n# Create GPU instance with small iteration count\ntest_sustain = TorchOrdinalSustain(\n    prob_nl, \n    prob_score, \n    score_vals, \n    biomarker_labels,\n    N_startpoints=5,               # Small for testing\n    N_S_max=1,                     # Single subtype for testing\n    N_iterations_MCMC=1000,        # Small for quick test\n    output_folder=test_output,\n    dataset_name=\"quicktest\",\n    use_parallel_startpoints=False,\n    seed=42,\n    use_gpu=True,                  # ENABLE GPU!\n    device_id=0\n)\n\n# Check GPU status\nif test_sustain.use_gpu:\n    print(\"\\n‚úÖ GPU initialized successfully!\")\n    print(f\"   ‚Ä¢ Device: {test_sustain.torch_backend.device_manager.device}\")\n    print(f\"   ‚Ä¢ Expected speedup: 8-15x on T4, 15-25x on A100\")\nelse:\n    print(\"\\n‚ö†Ô∏è  GPU not available, running on CPU\")\n    print(\"   Check: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n\n# Run test with progress tracking\nprint(\"\\nüöÄ Running quick test...\")\nprint(f\"‚è∞ Started: {datetime.now().strftime('%H:%M:%S')}\")\nprint(\"\\n\" + \"-\"*70)\n\nstart_time = time.time()\ntest_sustain.run_sustain_algorithm()\ntest_time = time.time() - start_time\n\nprint(\"-\"*70)\nprint(f\"‚è∞ Finished: {datetime.now().strftime('%H:%M:%S')}\")\nprint(f\"‚úÖ Test completed in {test_time:.1f} seconds\")\n\n# Estimate full run time\nfull_iterations = 100000\ntest_iterations = 1000\nestimated_time = test_time * (full_iterations / test_iterations)\nestimated_hours = estimated_time / 3600\nestimated_days = estimated_hours / 24\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üìä PROJECTIONS FOR FULL RUN\")\nprint(\"=\"*70)\nprint(f\"Full run parameters: {full_iterations} MCMC iterations, 25 startpoints, 3 subtypes\")\nprint(f\"\\nEstimated runtime:\")\nprint(f\"   ‚Ä¢ Hours: {estimated_hours:.1f} hours\")\nprint(f\"   ‚Ä¢ Days: {estimated_days:.1f} days\")\n\nif estimated_days < 30:\n    speedup = 30 / estimated_days\n    time_saved = 30 - estimated_days\n    print(f\"\\n‚ö° GPU Speedup:\")\n    print(f\"   ‚Ä¢ {speedup:.1f}x faster than CPU (30 days)\")\n    print(f\"   ‚Ä¢ Time saved: {time_saved:.1f} days\")\n    print(f\"\\n‚úÖ GPU is working! Ready for full analysis.\")\nelse:\n    print(f\"\\n‚ö†Ô∏è  Warning: Estimated time seems slow. GPU may not be active.\")\n\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keep-alive"
   },
   "source": [
    "## üîÑ Keep Colab Alive (For Multi-Day Runs)\n",
    "\n",
    "**‚ö†Ô∏è Colab disconnects after ~12 hours of inactivity!**\n",
    "\n",
    "### Option 1: Auto-Click Connect Button\n",
    "1. Open browser console: Press `F12` (Chrome/Firefox) or `Cmd+Option+J` (Mac)\n",
    "2. Paste this code and press Enter:\n",
    "```javascript\n",
    "function ClickConnect(){\n",
    "  console.log(\"Clicking connect...\");\n",
    "  document.querySelector(\"colab-connect-button\").click();\n",
    "}\n",
    "setInterval(ClickConnect, 60000); // Click every minute\n",
    "```\n",
    "\n",
    "### Option 2: Colab Pro/Pro+ (Recommended for Multi-Day)\n",
    "- **Colab Pro** ($10/month): Longer sessions, better GPUs\n",
    "- **Colab Pro+** ($50/month): Background execution, longest sessions\n",
    "\n",
    "### Option 3: Run Cell Below (Keep Output Active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell-keep-alive"
   },
   "outputs": [],
   "source": [
    "# This helps prevent disconnection by keeping output active\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "print(\"‚úÖ Output manager enabled - helps prevent disconnection\")\n",
    "print(\"üí° Still recommended: Use browser console auto-click (see above)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "full-run"
   },
   "source": [
    "## 6Ô∏è‚É£ Full GPU-Accelerated Analysis\n",
    "\n",
    "**üö® BEFORE RUNNING:**\n",
    "1. ‚úÖ Verify quick test (Cell 5) showed good speedup\n",
    "2. ‚úÖ Set up keep-alive (Cell above)\n",
    "3. ‚úÖ Consider Colab Pro/Pro+ for multi-day runs\n",
    "4. ‚úÖ (Optional) Change output folder to Google Drive for persistent storage\n",
    "\n",
    "**‚è∞ This will take 2-4 days even on GPU!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell-6"
   },
   "outputs": [],
   "source": "from pySuStaIn.TorchOrdinalSustain import TorchOrdinalSustain\nimport time\nfrom datetime import timedelta, datetime\nimport os\n\nprint(\"=\"*70)\nprint(\"üî¨ FULL GPU-ACCELERATED ANALYSIS\")\nprint(\"=\"*70)\n\n# Output folder (change to Google Drive if mounted)\noutput_folder = \"./gpu_sustain_output\"  \n# output_folder = \"/content/drive/MyDrive/sustain_output\"  # Uncomment for Google Drive\nos.makedirs(output_folder, exist_ok=True)\n\n# Create GPU instance with full parameters\ngpu_sustain = TorchOrdinalSustain(\n    prob_nl, \n    prob_score, \n    score_vals, \n    biomarker_labels,\n    N_startpoints=25,              # Full startpoints\n    N_S_max=3,                     # 3 subtypes\n    N_iterations_MCMC=100000,      # Full MCMC iterations\n    output_folder=output_folder,\n    dataset_name=\"ordinal_gpu_analysis\",\n    use_parallel_startpoints=False,\n    seed=42,\n    use_gpu=True,                  # GPU ENABLED\n    device_id=0\n)\n\n# Verify GPU\nif gpu_sustain.use_gpu:\n    print(\"\\n‚úÖ GPU confirmed active!\")\n    print(f\"   ‚Ä¢ Device: {gpu_sustain.torch_backend.device_manager.device}\")\nelse:\n    print(\"\\n‚ö†Ô∏è  WARNING: GPU not available, will use CPU (very slow!)\")\n    response = input(\"Continue anyway? (yes/no): \")\n    if response.lower() != 'yes':\n        raise RuntimeError(\"GPU not available. Please enable GPU runtime.\")\n\n# Show estimated runtime from quick test\ntry:\n    print(f\"\\n‚è∞ Estimated runtime: ~{estimated_days:.1f} days\")\nexcept:\n    print(\"\\n‚è∞ Estimated runtime: ~2-4 days on T4 GPU, ~1.5-2 days on A100\")\n\nprint(\"\\nüö® IMPORTANT:\")\nprint(\"   ‚Ä¢ Keep this tab/window open\")\nprint(\"   ‚Ä¢ Keep browser console auto-click running (if using)\")\nprint(\"   ‚Ä¢ Consider Colab Pro/Pro+ for better reliability\")\nprint(\"   ‚Ä¢ Results automatically saved to pickle files\")\n\nprint(\"\\n\" + \"=\"*70)\ninput(\"Press Enter to start full analysis...\")\nprint(\"=\"*70)\n\n# Progress tracking\ndef print_progress(stage, current=None, total=None):\n    \"\"\"Print formatted progress update\"\"\"\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    if current is not None and total is not None:\n        print(f\"[{timestamp}] {stage} ({current}/{total})\")\n    else:\n        print(f\"[{timestamp}] {stage}\")\n\n# START THE ANALYSIS\nstart_time = time.time()\nstart_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\nprint(\"\\n\" + \"=\"*70)\nprint_progress(\"üöÄ ANALYSIS STARTED\")\nprint(\"=\"*70)\n\n# Track progress through pickle file checks\nn_s_max = 3\nfor n_s in range(1, n_s_max + 1):\n    print(f\"\\n{'='*70}\")\n    print_progress(f\"üìä Processing N={n_s} subtype model\", n_s, n_s_max)\n    print(f\"{'='*70}\")\n    \n    subtype_start = time.time()\n    \n    # Check if this subtype already exists (from pickle)\n    pickle_file = os.path.join(output_folder, \"pickle_files\", \n                               f\"ordinal_gpu_analysis_subtype{n_s-1}.pickle\")\n    \n    if os.path.exists(pickle_file):\n        print(f\"   ‚úÖ Found existing results for N={n_s}\")\n        print(f\"   üìÇ Pickle file: {pickle_file}\")\n    else:\n        print(f\"   ‚öôÔ∏è  Running inference for N={n_s} subtypes...\")\n        print(f\"   ‚è∞ This may take several hours...\")\n\n# RUN!\nprint(f\"\\n{'='*70}\")\nprint_progress(\"‚öôÔ∏è  Running SuStaIn algorithm (this will take days)...\")\nprint(f\"{'='*70}\\n\")\n\nsamples_sequence, samples_f, ml_subtype, prob_ml_subtype, \\\nml_stage, prob_ml_stage, prob_subtype_stage = gpu_sustain.run_sustain_algorithm()\n\n# Calculate runtime\nend_time = time.time()\nend_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\nruntime = end_time - start_time\nruntime_str = str(timedelta(seconds=int(runtime)))\nruntime_hours = runtime / 3600\nruntime_days = runtime_hours / 24\n\n# Results summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ ANALYSIS COMPLETE!\")\nprint(\"=\"*70)\nprint(f\"Started:  {start_timestamp}\")\nprint(f\"Finished: {end_timestamp}\")\nprint(f\"Runtime:  {runtime_str} ({runtime_hours:.1f} hours = {runtime_days:.1f} days)\")\n\n# Show speedup\nif runtime_days < 30:\n    speedup = 30 / runtime_days\n    print(f\"\\n‚ö° GPU Speedup Achieved:\")\n    print(f\"   ‚Ä¢ {speedup:.1f}x faster than CPU estimate\")\n    print(f\"   ‚Ä¢ Time saved: {30 - runtime_days:.1f} days\")\n\nprint(f\"\\nüìÅ Results saved to: {output_folder}\")\nprint(\"\\nüìä Output files:\")\n!ls -lh {output_folder}\n\n# Show pickle files\npickle_folder = os.path.join(output_folder, \"pickle_files\")\nif os.path.exists(pickle_folder):\n    print(\"\\nüì¶ Pickle files (models for each N):\")\n    !ls -lh {pickle_folder}\n\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-results"
   },
   "source": [
    "## 7Ô∏è‚É£ Download Results\n",
    "\n",
    "After analysis completes, download the results to your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell-7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "print(\"üì¶ Preparing results for download...\")\n",
    "\n",
    "# Create zip file\n",
    "output_folder = \"./gpu_sustain_output\"  # Match the folder from Cell 6\n",
    "zip_filename = \"sustain_results\"\n",
    "\n",
    "if os.path.exists(output_folder):\n",
    "    shutil.make_archive(zip_filename, 'zip', output_folder)\n",
    "    print(f\"\\n‚úÖ Results packaged: {zip_filename}.zip\")\n",
    "    print(f\"   Size: {os.path.getsize(zip_filename + '.zip') / 1024**2:.1f} MB\")\n",
    "    \n",
    "    # Download\n",
    "    print(\"\\nüì• Starting download...\")\n",
    "    files.download(f\"{zip_filename}.zip\")\n",
    "    print(\"‚úÖ Download complete!\")\n",
    "else:\n",
    "    print(f\"‚ùå Output folder not found: {output_folder}\")\n",
    "    print(\"   Make sure analysis has completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "footer"
   },
   "source": [
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- **SuStaIn Documentation**: [pySuStaIn GitHub](https://github.com/ucl-pond/pySuStaIn)\n",
    "- **Google Colab Tips**: [Research Colab FAQ](https://research.google.com/colaboratory/faq.html)\n",
    "- **GPU Optimization**: See `TorchOrdinalSustain.py` in the repository\n",
    "\n",
    "## üÜò Troubleshooting\n",
    "\n",
    "**GPU not detected?**\n",
    "- Runtime ‚Üí Change runtime type ‚Üí Select GPU ‚Üí Save\n",
    "- Restart runtime and re-run from Cell 1\n",
    "\n",
    "**Session disconnected?**\n",
    "- Results are saved in pickle files automatically\n",
    "- Reload and check output folder for partial results\n",
    "- Use browser console auto-click (see Cell above)\n",
    "\n",
    "**Out of memory?**\n",
    "- Try reducing `N_startpoints` to 10-15\n",
    "- Upgrade to Colab Pro for more RAM\n",
    "\n",
    "**Too slow?**\n",
    "- Verify GPU is active (check Cell 5 output)\n",
    "- Try A100 GPU (Colab Pro)\n",
    "- Check CUDA is being used in test output\n",
    "\n",
    "---\n",
    "\n",
    "**Created by**: GPU-optimized SuStaIn pipeline  \n",
    "**Version**: TorchOrdinalSustain with CUDA acceleration  \n",
    "**Last Updated**: 2025-11-17"
   ]
  },
  {
   "cell_type": "code",
   "source": "import os\n\n# Create scripts directory\nscripts_dir = \"./parallel_scripts\"\nos.makedirs(scripts_dir, exist_ok=True)\n\n# Template for each N value script\nscript_template = \"\"\"#!/usr/bin/env python3\n'''\nGPU-Accelerated OrdinalSustain for N={n_subtypes} subtypes\nDevice: GPU {device_id}\nGenerated: {timestamp}\n'''\n\nimport numpy as np\nimport sys\nimport time\nfrom datetime import datetime, timedelta\n\n# Add pySuStaIn to path\nsys.path.insert(0, '/path/to/mphil')  # UPDATE THIS PATH!\n\nfrom pySuStaIn.TorchOrdinalSustain import TorchOrdinalSustain\n\ndef print_progress(msg):\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    print(f\"[{{timestamp}}] N={n_subtypes} GPU{device_id}: {{msg}}\")\n    sys.stdout.flush()\n\nprint(\"=\"*70)\nprint_progress(\"STARTING\")\nprint(\"=\"*70)\n\n# Load your data here\nprint_progress(\"Loading data...\")\n# TODO: Replace with your actual data loading\n# prob_nl = np.load('your_prob_nl.npy')\n# prob_score = np.load('your_prob_score.npy')  \n# score_vals = np.load('your_score_vals.npy')\n# biomarker_labels = ['Domain1', 'Domain2', ...]\n\n# For now, generate test data\ndef generate_test_data(n_subjects=7000, n_biomarkers=13, n_scores=3, seed=42):\n    np.random.seed(seed)\n    p_correct = 0.9\n    p_nl_dist = np.full((n_scores + 1), (1 - p_correct) / n_scores)\n    p_nl_dist[0] = p_correct\n    p_score_dist = np.full((n_scores, n_scores + 1), (1 - p_correct) / n_scores)\n    for score in range(n_scores):\n        p_score_dist[score, score + 1] = p_correct\n    data = np.random.choice(range(n_scores + 1), n_subjects * n_biomarkers,\n                          replace=True, p=p_nl_dist)\n    data = data.reshape((n_subjects, n_biomarkers))\n    prob_nl = p_nl_dist[data]\n    prob_score = np.zeros((n_subjects, n_biomarkers, n_scores))\n    for n in range(n_biomarkers):\n        for z in range(n_scores):\n            for score in range(n_scores + 1):\n                prob_score[data[:, n] == score, n, z] = p_score_dist[z, score]\n    score_vals = np.tile(np.arange(1, n_scores + 1), (n_biomarkers, 1))\n    biomarker_labels = [f\"Biomarker_{{i}}\" for i in range(n_biomarkers)]\n    return prob_nl, prob_score, score_vals, biomarker_labels\n\nprob_nl, prob_score, score_vals, biomarker_labels = generate_test_data()\nprint_progress(f\"Data loaded: {{prob_nl.shape[0]}} subjects, {{prob_nl.shape[1]}} biomarkers\")\n\n# Initialize model\nprint_progress(\"Initializing TorchOrdinalSustain...\")\noutput_folder = f\"./output_N{n_subtypes}_GPU{device_id}\"\n\nsustain = TorchOrdinalSustain(\n    prob_nl, \n    prob_score, \n    score_vals, \n    biomarker_labels,\n    N_startpoints=25,\n    N_S_max={n_subtypes},\n    N_iterations_MCMC=10000,       # Adjust for your needs\n    output_folder=output_folder,\n    dataset_name=f\"EDS_POTS_N{n_subtypes}\",\n    use_parallel_startpoints=False,\n    seed=42,\n    use_gpu=True,\n    device_id={device_id}\n)\n\nif not sustain.use_gpu:\n    print_progress(\"ERROR: GPU not available!\")\n    sys.exit(1)\n\nprint_progress(f\"GPU {{sustain.torch_backend.device_manager.device}} confirmed\")\n\n# Run analysis\nprint_progress(\"Running SuStaIn algorithm...\")\nstart_time = time.time()\n\nsamples_sequence, samples_f, ml_subtype, prob_ml_subtype, \\\\\nml_stage, prob_ml_stage, prob_subtype_stage = sustain.run_sustain_algorithm()\n\nruntime = time.time() - start_time\nruntime_str = str(timedelta(seconds=int(runtime)))\n\nprint(\"=\"*70)\nprint_progress(f\"COMPLETE! Runtime: {{runtime_str}}\")\nprint_progress(f\"Results: {{output_folder}}\")\nprint(\"=\"*70)\n\"\"\"\n\n# Generate script for each N value\nfrom datetime import datetime\ntimestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\nfor n in range(1, 7):  # N=1 to N=6\n    device_id = n - 1  # GPU 0-5\n    script_content = script_template.format(\n        n_subtypes=n,\n        device_id=device_id,\n        timestamp=timestamp\n    )\n    \n    script_path = os.path.join(scripts_dir, f\"run_N{n}_GPU{device_id}.py\")\n    with open(script_path, 'w') as f:\n        f.write(script_content)\n    \n    # Make executable\n    os.chmod(script_path, 0o755)\n    \n    print(f\"‚úÖ Created: {script_path}\")\n\n# Create master launch script\nlaunch_script = \"\"\"#!/bin/bash\n# Launch all N values in parallel across 6 GPUs\n# Generated: {timestamp}\n\necho \"Launching parallel GPU jobs...\"\necho \"======================================================================\"\n\n# Launch each script in background\nfor N in 1 2 3 4 5 6; do\n    GPU=$((N-1))\n    echo \"Starting N=$N on GPU $GPU...\"\n    nohup python3 run_N${{N}}_GPU${{GPU}}.py > log_N${{N}}_GPU${{GPU}}.txt 2>&1 &\n    echo \"  PID: $!\"\ndone\n\necho \"======================================================================\"\necho \"All jobs launched!\"\necho \"Monitor with: tail -f log_N*_GPU*.txt\"\necho \"Check status: ps aux | grep run_N\"\n\"\"\".format(timestamp=timestamp)\n\nlaunch_path = os.path.join(scripts_dir, \"launch_all.sh\")\nwith open(launch_path, 'w') as f:\n    f.write(launch_script)\nos.chmod(launch_path, 0o755)\n\nprint(f\"\\n‚úÖ Created master launcher: {launch_path}\")\nprint(f\"\\nüìÇ All scripts in: {scripts_dir}/\")\nprint(\"\\nüìã To run on GBSH:\")\nprint(\"   1. Copy these scripts to your GBSH server\")\nprint(\"   2. Update data paths in each script\")\nprint(f\"   3. Run: cd {scripts_dir} && ./launch_all.sh\")\nprint(\"   4. Monitor: tail -f log_N*.txt\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8Ô∏è‚É£ Generate Parallel Execution Scripts (For GBSH Multi-GPU)\n\nIf you want to run N=1-6 in parallel across 6 GPUs on your GBSH servers, run this cell to generate standalone Python scripts.",
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}