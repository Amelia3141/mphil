{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# \ud83d\udd25 GPU-Accelerated OrdinalSustain Test\n",
    "\n",
    "This notebook tests the GPU-accelerated OrdinalSustain implementation on Google Colab.\n",
    "\n",
    "## \ud83d\udccb What this notebook does:\n",
    "1. \u2705 Verifies GPU availability\n",
    "2. \u2705 Clones the repository with GPU implementation\n",
    "3. \u2705 Installs dependencies\n",
    "4. \u2705 Tests GPU vs CPU performance\n",
    "5. \u2705 Validates correctness (GPU results match CPU)\n",
    "6. \u2705 Benchmarks across different dataset sizes\n",
    "\n",
    "## \u2699\ufe0f Before running:\n",
    "**IMPORTANT:** Enable GPU in Colab!\n",
    "- Click `Runtime` \u2192 `Change runtime type`\n",
    "- Select `T4 GPU` under Hardware accelerator\n",
    "- Click `Save`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section1"
   },
   "source": [
    "## 1\ufe0f\u20e3 Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udd0d GPU DETECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if nvidia-smi works\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n\u2705 GPU detected!\\n\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(\"\\n\u26a0\ufe0f  nvidia-smi failed. GPU may not be enabled.\")\n",
    "        print(\"Please enable GPU: Runtime \u2192 Change runtime type \u2192 GPU\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n\u274c nvidia-smi not found. GPU is not available.\")\n",
    "    print(\"Please enable GPU: Runtime \u2192 Change runtime type \u2192 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section2"
   },
   "source": [
    "## 2\ufe0f\u20e3 Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udce6 INSTALLING DEPENDENCIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Install core dependencies\n",
    "print(\"\\n\ud83d\udce6 Installing core packages...\")\n",
    "!pip install -q torch numpy scipy matplotlib tqdm scikit-learn pandas pathos dill\n",
    "\n",
    "# Install awkde and kde_ebm (may take ~30 seconds)\n",
    "print(\"\ud83d\udce6 Installing awkde and kde_ebm (this may take ~30 seconds)...\")\n",
    "!pip install -q git+https://github.com/noxtoby/awkde.git\n",
    "!pip install -q git+https://github.com/ucl-pond/kde_ebm.git\n",
    "\n",
    "print(\"\\n\u2705 All dependencies installed!\")\n",
    "\n",
    "# Verify PyTorch can see GPU\n",
    "import torch\n",
    "print(f\"\\n\ud83d\udd27 PyTorch GPU Info:\")\n",
    "print(f\"   \u2022 PyTorch version: {torch.__version__}\")\n",
    "print(f\"   \u2022 CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   \u2022 CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"   \u2022 GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   \u2022 GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"   \u26a0\ufe0f  CUDA not available. Please enable GPU runtime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section3"
   },
   "source": [
    "## 3\ufe0f\u20e3 Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udce5 CLONING REPOSITORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Remove existing directory if it exists\n",
    "!rm -rf mphil\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/Amelia3141/mphil.git\n",
    "\n",
    "# Change to repository directory\n",
    "%cd mphil\n",
    "\n",
    "# Checkout the GPU optimization branch\n",
    "!git checkout claude/optimize-sustain-speed-011CV4Lk8FuUjS6hZNj13WE3\n",
    "\n",
    "# Add to Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/content/mphil')\n",
    "\n",
    "print(\"\\n\u2705 Repository cloned and branch checked out!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section4"
   },
   "source": [
    "## 4\ufe0f\u20e3 Generate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_data"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83c\udfb2 GENERATING TEST DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def generate_test_data(n_subjects=1000, n_biomarkers=10, n_scores=3, seed=42):\n",
    "    \"\"\"Generate synthetic test data for OrdinalSustain.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Set the proportion of individuals with correct scores to 0.9\n",
    "    p_correct = 0.9\n",
    "    p_nl_dist = np.full((n_scores + 1), (1 - p_correct) / n_scores)\n",
    "    p_nl_dist[0] = p_correct\n",
    "    \n",
    "    p_score_dist = np.full((n_scores, n_scores + 1), (1 - p_correct) / n_scores)\n",
    "    for score in range(n_scores):\n",
    "        p_score_dist[score, score + 1] = p_correct\n",
    "    \n",
    "    # Generate data\n",
    "    data = np.random.choice(range(n_scores + 1), n_subjects * n_biomarkers,\n",
    "                          replace=True, p=p_nl_dist)\n",
    "    data = data.reshape((n_subjects, n_biomarkers))\n",
    "    \n",
    "    # Turn the data into probabilities\n",
    "    prob_nl = p_nl_dist[data]\n",
    "    \n",
    "    prob_score = np.zeros((n_subjects, n_biomarkers, n_scores))\n",
    "    for n in range(n_biomarkers):\n",
    "        for z in range(n_scores):\n",
    "            for score in range(n_scores + 1):\n",
    "                prob_score[data[:, n] == score, n, z] = p_score_dist[z, score]\n",
    "    \n",
    "    # Create score_vals matrix\n",
    "    score_vals = np.tile(np.arange(1, n_scores + 1), (n_biomarkers, 1))\n",
    "    \n",
    "    # Create biomarker labels\n",
    "    biomarker_labels = [f\"Biomarker_{i}\" for i in range(n_biomarkers)]\n",
    "    \n",
    "    return prob_nl, prob_score, score_vals, biomarker_labels\n",
    "\n",
    "# Generate test data\n",
    "prob_nl, prob_score, score_vals, biomarker_labels = generate_test_data(\n",
    "    n_subjects=1000, n_biomarkers=10, n_scores=3\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2705 Test data generated:\")\n",
    "print(f\"   \u2022 Subjects: {prob_nl.shape[0]}\")\n",
    "print(f\"   \u2022 Biomarkers: {prob_nl.shape[1]}\")\n",
    "print(f\"   \u2022 Scores: {prob_score.shape[2]}\")\n",
    "print(f\"   \u2022 prob_nl shape: {prob_nl.shape}\")\n",
    "print(f\"   \u2022 prob_score shape: {prob_score.shape}\")\n",
    "print(f\"   \u2022 score_vals shape: {score_vals.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section5"
   },
   "source": [
    "## 5\ufe0f\u20e3 Test GPU Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_gpu"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pySuStaIn.TorchOrdinalSustain import TorchOrdinalSustain\n",
    "from pySuStaIn.OrdinalSustain import OrdinalSustain\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udd25 TESTING GPU IMPLEMENTATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Create GPU instance\n",
    "    gpu_sustain = TorchOrdinalSustain(\n",
    "        prob_nl, prob_score, score_vals, biomarker_labels,\n",
    "        N_startpoints=1,\n",
    "        N_S_max=1,\n",
    "        N_iterations_MCMC=100,\n",
    "        output_folder=\"./temp\",\n",
    "        dataset_name=\"gpu_test\",\n",
    "        use_parallel_startpoints=False,\n",
    "        seed=42,\n",
    "        use_gpu=True,\n",
    "        device_id=0\n",
    "    )\n",
    "    \n",
    "    if gpu_sustain.use_gpu:\n",
    "        print(\"\\n\u2705 GPU implementation initialized successfully!\")\n",
    "        print(f\"   \u2022 Using device: {gpu_sustain.torch_backend.device_manager.device}\")\n",
    "        print(f\"   \u2022 Data type: {gpu_sustain.torch_backend.device_manager.torch_dtype}\")\n",
    "    else:\n",
    "        print(\"\\n\u26a0\ufe0f  GPU not available, running on CPU\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n\u274c Error initializing GPU implementation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section6"
   },
   "source": [
    "## 6\ufe0f\u20e3 Validate Correctness (GPU vs CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udd2c VALIDATION: GPU vs CPU Correctness\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if not gpu_sustain.use_gpu:\n",
    "    print(\"\\n\u26a0\ufe0f  Skipping validation - GPU not available\")\n",
    "else:\n",
    "    # Create CPU instance for comparison\n",
    "    cpu_sustain = OrdinalSustain(\n",
    "        prob_nl, prob_score, score_vals, biomarker_labels,\n",
    "        N_startpoints=1,\n",
    "        N_S_max=1,\n",
    "        N_iterations_MCMC=100,\n",
    "        output_folder=\"./temp\",\n",
    "        dataset_name=\"cpu_test\",\n",
    "        use_parallel_startpoints=False,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Get sustainData\n",
    "    cpu_data = getattr(cpu_sustain, '_OrdinalSustain__sustainData')\n",
    "    gpu_data = getattr(gpu_sustain, '_OrdinalSustain__sustainData')\n",
    "    \n",
    "    # Test with random sequences\n",
    "    # Get the actual number of stages from the sustain object\n",
    "    N = cpu_data.getNumStages()\n",
    "    n_tests = 5\n",
    "    all_passed = True\n",
    "    tolerance = 1e-5\n",
    "    \n",
    "    for test_idx in range(n_tests):\n",
    "        # Generate random sequence\n",
    "        np.random.seed(test_idx)\n",
    "        S_test = np.random.permutation(N).astype(float)\n",
    "        \n",
    "        # Compute likelihoods\n",
    "        cpu_result = cpu_sustain._calculate_likelihood_stage(cpu_data, S_test)\n",
    "        gpu_result = gpu_sustain._calculate_likelihood_stage(gpu_data, S_test)\n",
    "        \n",
    "        # Compare results\n",
    "        max_diff = np.max(np.abs(cpu_result - gpu_result))\n",
    "        mean_diff = np.mean(np.abs(cpu_result - gpu_result))\n",
    "        rel_diff = max_diff / (np.mean(np.abs(cpu_result)) + 1e-10)\n",
    "        \n",
    "        print(f\"\\nTest {test_idx + 1}/{n_tests}:\")\n",
    "        print(f\"   \u2022 Max absolute diff: {max_diff:.2e}\")\n",
    "        print(f\"   \u2022 Mean absolute diff: {mean_diff:.2e}\")\n",
    "        print(f\"   \u2022 Relative diff: {rel_diff:.2e}\")\n",
    "        \n",
    "        if max_diff > tolerance:\n",
    "            print(f\"   \u274c FAILED (exceeds tolerance {tolerance:.2e})\")\n",
    "            all_passed = False\n",
    "        else:\n",
    "            print(f\"   \u2705 PASSED\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    if all_passed:\n",
    "        print(\"\u2705 All validation tests PASSED!\")\n",
    "        print(\"   GPU results match CPU within numerical tolerance\")\n",
    "    else:\n",
    "        print(\"\u274c Some validation tests FAILED\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section7"
   },
   "source": [
    "## 7\ufe0f\u20e3 Performance Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "benchmark"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"\u26a1 PERFORMANCE BENCHMARK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if not gpu_sustain.use_gpu:\n",
    "    print(\"\\n\u26a0\ufe0f  Skipping benchmark - GPU not available\")\n",
    "else:\n",
    "    # Prepare test sequence\n",
    "    # Get the actual number of stages from the sustain object\n",
    "    N = cpu_data.getNumStages()\n",
    "    S_test = np.random.permutation(N).astype(float)\n",
    "    \n",
    "    n_iterations = 20\n",
    "    \n",
    "    # Benchmark CPU\n",
    "    print(f\"\\n\ud83d\udc0c Benchmarking CPU ({n_iterations} iterations)...\")\n",
    "    cpu_times = []\n",
    "    for i in range(n_iterations):\n",
    "        start = time.time()\n",
    "        _ = cpu_sustain._calculate_likelihood_stage(cpu_data, S_test)\n",
    "        cpu_times.append(time.time() - start)\n",
    "    \n",
    "    cpu_mean = np.mean(cpu_times)\n",
    "    cpu_std = np.std(cpu_times)\n",
    "    \n",
    "    print(f\"   \u2022 Mean time: {cpu_mean*1000:.2f}ms \u00b1 {cpu_std*1000:.2f}ms\")\n",
    "    print(f\"   \u2022 Min time: {np.min(cpu_times)*1000:.2f}ms\")\n",
    "    print(f\"   \u2022 Max time: {np.max(cpu_times)*1000:.2f}ms\")\n",
    "    \n",
    "    # Benchmark GPU (with warmup)\n",
    "    print(f\"\\n\ud83d\udd25 Benchmarking GPU ({n_iterations} iterations)...\")\n",
    "    print(\"   \u2022 Warming up GPU...\")\n",
    "    for _ in range(5):\n",
    "        _ = gpu_sustain._calculate_likelihood_stage(gpu_data, S_test)\n",
    "    \n",
    "    gpu_times = []\n",
    "    for i in range(n_iterations):\n",
    "        start = time.time()\n",
    "        _ = gpu_sustain._calculate_likelihood_stage(gpu_data, S_test)\n",
    "        gpu_times.append(time.time() - start)\n",
    "    \n",
    "    gpu_mean = np.mean(gpu_times)\n",
    "    gpu_std = np.std(gpu_times)\n",
    "    \n",
    "    print(f\"   \u2022 Mean time: {gpu_mean*1000:.2f}ms \u00b1 {gpu_std*1000:.2f}ms\")\n",
    "    print(f\"   \u2022 Min time: {np.min(gpu_times)*1000:.2f}ms\")\n",
    "    print(f\"   \u2022 Max time: {np.max(gpu_times)*1000:.2f}ms\")\n",
    "    \n",
    "    # Calculate speedup\n",
    "    speedup = cpu_mean / gpu_mean\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"\ud83d\ude80 SPEEDUP: {speedup:.2f}x\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n\ud83d\udcca Summary:\")\n",
    "    print(f\"   \u2022 Dataset: {prob_nl.shape[0]} subjects, {prob_nl.shape[1]} biomarkers\")\n",
    "    print(f\"   \u2022 CPU time: {cpu_mean*1000:.2f}ms\")\n",
    "    print(f\"   \u2022 GPU time: {gpu_mean*1000:.2f}ms\")\n",
    "    print(f\"   \u2022 Speedup: {speedup:.2f}x faster on GPU\")\n",
    "    \n",
    "    # Get GPU performance stats\n",
    "    perf_stats = gpu_sustain.get_performance_stats()\n",
    "    if perf_stats['computation_times']:\n",
    "        print(\"\\n\u23f1\ufe0f  Detailed GPU timing:\")\n",
    "        for op_name, op_time in perf_stats['computation_times'].items():\n",
    "            print(f\"   \u2022 {op_name}: {op_time*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section8"
   },
   "source": [
    "## 8\ufe0f\u20e3 Benchmark Across Dataset Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "benchmark_sizes"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udcc8 BENCHMARK ACROSS DATASET SIZES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if not gpu_sustain.use_gpu:\n",
    "    print(\"\\n\u26a0\ufe0f  Skipping - GPU not available\")\n",
    "else:\n",
    "    configs = [\n",
    "        {\"n_subjects\": 100, \"n_biomarkers\": 5, \"n_scores\": 3},\n",
    "        {\"n_subjects\": 500, \"n_biomarkers\": 10, \"n_scores\": 3},\n",
    "        {\"n_subjects\": 1000, \"n_biomarkers\": 10, \"n_scores\": 3},\n",
    "        {\"n_subjects\": 2000, \"n_biomarkers\": 15, \"n_scores\": 3},\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for config in configs:\n",
    "        print(f\"\\n{'\u2500'*70}\")\n",
    "        print(f\"Testing: {config['n_subjects']} subjects, {config['n_biomarkers']} biomarkers\")\n",
    "        print('\u2500'*70)\n",
    "        \n",
    "        # Generate data\n",
    "        test_prob_nl, test_prob_score, test_score_vals, test_labels = generate_test_data(**config)\n",
    "        \n",
    "        # Create instances\n",
    "        test_cpu = OrdinalSustain(\n",
    "            test_prob_nl, test_prob_score, test_score_vals, test_labels,\n",
    "            1, 1, 100, \"./temp\", \"test\", False, 42\n",
    "        )\n",
    "        test_gpu = TorchOrdinalSustain(\n",
    "            test_prob_nl, test_prob_score, test_score_vals, test_labels,\n",
    "            1, 1, 100, \"./temp\", \"test\", False, 42, use_gpu=True\n",
    "        )\n",
    "        \n",
    "        # Get data\n",
    "        test_cpu_data = getattr(test_cpu, '_OrdinalSustain__sustainData')\n",
    "        test_gpu_data = getattr(test_gpu, '_OrdinalSustain__sustainData')\n",
    "        \n",
    "        # Prepare sequence\n",
    "        # Get the actual number of stages from the sustain object\n",
    "        test_N = test_cpu_data.getNumStages()\n",
    "        test_S = np.random.permutation(test_N).astype(float)\n",
    "        \n",
    "        # Benchmark CPU\n",
    "        cpu_times_test = []\n",
    "        for _ in range(10):\n",
    "            start = time.time()\n",
    "            _ = test_cpu._calculate_likelihood_stage(test_cpu_data, test_S)\n",
    "            cpu_times_test.append(time.time() - start)\n",
    "        \n",
    "        # Benchmark GPU (with warmup)\n",
    "        for _ in range(3):\n",
    "            _ = test_gpu._calculate_likelihood_stage(test_gpu_data, test_S)\n",
    "        \n",
    "        gpu_times_test = []\n",
    "        for _ in range(10):\n",
    "            start = time.time()\n",
    "            _ = test_gpu._calculate_likelihood_stage(test_gpu_data, test_S)\n",
    "            gpu_times_test.append(time.time() - start)\n",
    "        \n",
    "        cpu_mean_test = np.mean(cpu_times_test)\n",
    "        gpu_mean_test = np.mean(gpu_times_test)\n",
    "        speedup_test = cpu_mean_test / gpu_mean_test\n",
    "        \n",
    "        results.append({\n",
    "            'subjects': config['n_subjects'],\n",
    "            'biomarkers': config['n_biomarkers'],\n",
    "            'cpu_time': cpu_mean_test,\n",
    "            'gpu_time': gpu_mean_test,\n",
    "            'speedup': speedup_test\n",
    "        })\n",
    "        \n",
    "        print(f\"   \u2022 CPU: {cpu_mean_test*1000:.2f}ms\")\n",
    "        print(f\"   \u2022 GPU: {gpu_mean_test*1000:.2f}ms\")\n",
    "        print(f\"   \u2022 Speedup: {speedup_test:.2f}x\")\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\ud83d\udcca SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n{'Subjects':<12} {'Biomarkers':<12} {'CPU (ms)':<12} {'GPU (ms)':<12} {'Speedup':<10}\")\n",
    "    print(\"\u2500\"*70)\n",
    "    for r in results:\n",
    "        print(f\"{r['subjects']:<12} {r['biomarkers']:<12} \"\n",
    "              f\"{r['cpu_time']*1000:<12.2f} {r['gpu_time']*1000:<12.2f} \"\n",
    "              f\"{r['speedup']:<10.2f}x\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udf89 Test Complete!\n",
    "\n",
    "### What we tested:\n",
    "1. \u2705 GPU detection and initialization\n",
    "2. \u2705 Correctness validation (GPU matches CPU results)\n",
    "3. \u2705 Performance benchmarking (GPU vs CPU speedup)\n",
    "4. \u2705 Scalability across dataset sizes\n",
    "\n",
    "### Expected Results:\n",
    "- **Speedup**: 8-15x on Google Colab T4 GPU\n",
    "- **Correctness**: GPU results match CPU within 1e-5 tolerance\n",
    "- **Scalability**: Speedup increases with dataset size\n",
    "\n",
    "### Next Steps:\n",
    "- Try with your own data\n",
    "- Experiment with different dataset sizes\n",
    "- Run full SuStaIn algorithm with `run_sustain_algorithm()`\n",
    "\n",
    "---\n",
    "\n",
    "**Repository:** https://github.com/Amelia3141/mphil\n",
    "\n",
    "**Branch:** `claude/optimize-sustain-speed-011CV4Lk8FuUjS6hZNj13WE3`\n",
    "\n",
    "**Documentation:** See `GPU_ORDINAL_OPTIMIZATION.md` in the repository\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}